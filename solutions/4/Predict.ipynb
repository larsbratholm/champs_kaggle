{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEUbn4AM4a6J"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "import math\n",
    "import dgl\n",
    "import torch\n",
    "import weakref\n",
    "import numbers\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import cytoolz.curried as ct\n",
    "import humanfriendly as hf\n",
    "import itertools\n",
    "\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "TRUE_MLKN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5c_iVNcN4BCR"
   },
   "outputs": [],
   "source": [
    "settings = json.load(open('SETTINGS.json'))\n",
    "\n",
    "models = settings['PREDICT']['MODELS']\n",
    "data = settings['PREDICT']['INPUT']\n",
    "mlk = settings['PREDICT']['Q9MLK']\n",
    "output = settings['PREDICT']['OUTPUT']\n",
    "\n",
    "CTYPES = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djjccOPGFN0b"
   },
   "source": [
    "## Data loading and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAF6aLnc5ttf"
   },
   "outputs": [],
   "source": [
    "test_data = torch.load(data)\n",
    "if TRUE_MLKN:\n",
    "    truemlkn = torch.load(mlk)\n",
    "    for i in range(len(test_data)):\n",
    "        natoms1 = test_data[i]['nodes']\n",
    "        natoms2 = len(truemlkn[i]['mlkn'])\n",
    "        assert natoms1==natoms2\n",
    "        test_data[i]['ndata']['mulliken'] = truemlkn[i]['mlkn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0r7CQwab4a7O"
   },
   "outputs": [],
   "source": [
    "def make_dglg(mol, precision='double'):\n",
    "    g = dgl.DGLGraph()\n",
    "    nodes = mol['nodes']\n",
    "    g.add_nodes(nodes)\n",
    "    src, dst = mol['src'], mol['dst']\n",
    "    g.ndata.update(mol['ndata'])\n",
    "    g.ndata['type'] = g.ndata['type']\n",
    "    g.add_edges(src, dst)\n",
    "    g.add_edges(dst, src)\n",
    "    g.add_edges(range(nodes), range(nodes))\n",
    "    \n",
    "    device = src.device\n",
    "    zeros = torch.zeros(nodes, dtype=torch.float32, device=device)\n",
    "    ones = torch.ones(nodes, dtype=torch.int64, device=device) \n",
    "    edata = {}\n",
    "    edata['type'] = torch.cat([mol['edata']['type'].repeat(2), ones * 6])\n",
    "    edata['distance'] = torch.cat([mol['edata']['distance'].repeat(2), zeros])\n",
    "    edata['angle'] = torch.cat([mol['edata']['angle'].repeat(2), zeros])\n",
    "    edata['dihedral'] = torch.cat([mol['edata']['dihedral'], -mol['edata']['dihedral'], zeros])\n",
    "    edata['coupling_type'] = torch.cat([mol['edata']['coupling_type'].repeat(2).to(torch.int64), -ones])\n",
    "    edata['coupling'] = torch.cat([mol['edata']['coupling'].repeat(2), zeros])\n",
    "    edata['train_id'] = torch.cat([mol['edata']['train_id'].repeat(2), -ones])\n",
    "    edata['test_id'] = torch.cat([mol['edata']['test_id'].repeat(2), -ones])\n",
    "\n",
    "    g.edata.update(edata)\n",
    "    return g\n",
    "\n",
    "  \n",
    "@ct.curry\n",
    "def make_graph_batch(mols, precision='double'):\n",
    "    g = dgl.batch([make_dglg(mol, precision) for mol in mols])\n",
    "    g.set_n_initializer(dgl.init.zero_initializer)\n",
    "    g.set_e_initializer(dgl.init.zero_initializer)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eHVq445rnKC"
   },
   "source": [
    "## Layers for building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN1DTva34a7W"
   },
   "outputs": [],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim):\n",
    "        super(Embed, self).__init__()\n",
    "        self.emb_node_types = nn.Embedding(10, node_dim-4)\n",
    "        self.emb_edge_types = nn.Embedding(10, edge_dim-3)\n",
    "        \n",
    "    def forward(self, g):\n",
    "        emb = self.emb_node_types(g.ndata['type'])\n",
    "        g.ndata['emb'] = torch.cat([\n",
    "            emb,\n",
    "            g.ndata['el_aff'].unsqueeze(1),\n",
    "            g.ndata['el_neg'].unsqueeze(1),\n",
    "            g.ndata['1st_ion'].unsqueeze(1),\n",
    "            g.ndata['mulliken'].unsqueeze(1)\n",
    "        ], dim=-1)\n",
    "        \n",
    "        emb = self.emb_edge_types(g.edata['type'])\n",
    "        g.edata['emb'] = torch.cat([\n",
    "            emb,\n",
    "            g.edata['distance'].unsqueeze(1),\n",
    "            g.edata['angle'].unsqueeze(1),\n",
    "            g.edata['dihedral'].unsqueeze(1),\n",
    "        ], dim=-1)\n",
    "        return g\n",
    "      \n",
    "\n",
    "class GraphCast(nn.Module):\n",
    "    def __init__(self, dtype):\n",
    "        super(GraphAct, self).__init__()\n",
    "        self.dtype = dtype\n",
    "    \n",
    "    def forward(self, g):\n",
    "        g.ndata['emb'] = g.ndata['emb'].to(self.dtype)\n",
    "        g.edata['emb'] = g.edata['emb'].to(self.dtype)\n",
    "        return g\n",
    "      \n",
    "    \n",
    "class EdgeSoftmax(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, g, score):\n",
    "        score_name = dgl.utils.get_edata_name(g, 'score')\n",
    "        tmp_name = dgl.utils.get_ndata_name(g, 'tmp')\n",
    "        out_name = dgl.utils.get_edata_name(g, 'out')\n",
    "        g.edata[score_name] = score\n",
    "        g.update_all(fn.copy_e(score_name, 'm'), fn.max('m', tmp_name))\n",
    "        g.apply_edges(fn.e_sub_v(score_name, tmp_name, out_name))\n",
    "        g.edata[out_name] = torch.exp(g.edata[out_name])\n",
    "        g.update_all(fn.copy_e(out_name, 'm'), fn.sum('m', tmp_name))\n",
    "        g.apply_edges(fn.e_div_v(out_name, tmp_name, out_name))\n",
    "        g.edata.pop(score_name)\n",
    "        g.ndata.pop(tmp_name)\n",
    "        out = g.edata.pop(out_name)\n",
    "        ctx.backward_cache = weakref.ref(g)\n",
    "        ctx.save_for_backward(out)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        g = ctx.backward_cache()\n",
    "        out, = ctx.saved_tensors\n",
    "        # clear backward cache explicitly\n",
    "        ctx.backward_cache = None\n",
    "        out_name = dgl.utils.get_edata_name(g, 'out')\n",
    "        accum_name = dgl.utils.get_ndata_name(g, 'accum')\n",
    "        grad_score_name = dgl.utils.get_edata_name(g, 'grad_score')\n",
    "        g.edata[out_name] = out\n",
    "        g.edata[grad_score_name] = out * grad_out\n",
    "        g.update_all(fn.copy_e(grad_score_name, 'm'), fn.sum('m', accum_name))\n",
    "        g.apply_edges(fn.e_mul_v(out_name, accum_name, out_name))\n",
    "        g.ndata.pop(accum_name)\n",
    "        grad_score = g.edata.pop(grad_score_name) - g.edata.pop(out_name)\n",
    "        return None, grad_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGg5vmhM4a7g"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, init=ct.curry(nn.init.xavier_normal_)(gain=1.414)):\n",
    "        self.init = init\n",
    "        super(Linear, self).__init__(in_features, out_features, bias)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.init(self.weight)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "    \n",
    "    \n",
    "class MultiLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_linears=1, bias=True,\n",
    "                init=ct.curry(nn.init.xavier_normal_)(gain=nn.init.calculate_gain('relu'))):\n",
    "        super(MultiLinear, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.n_linears = n_linears\n",
    "        self.in_features = in_features\n",
    "        self.init = init\n",
    "        weights = torch.zeros(n_linears, in_features, out_features, dtype=torch.float32)\n",
    "        init(weights)\n",
    "        self.lin = nn.Parameter(weights)\n",
    "        self.init(self.lin.data)\n",
    "        if bias:\n",
    "            b = torch.zeros((n_linears, 1, self.out_features), dtype=torch.float32)\n",
    "            self.bias = nn.Parameter(b)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "    def extra_repr(self):\n",
    "        return f'{self.in_features}, {self.out_features}, {self.n_linears}'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, self.n_linears, -1).permute(1, 0, 2)\n",
    "        if self.bias is not None:\n",
    "            y = torch.baddbmm(self.bias.expand(self.n_linears, batch, self.out_features),\n",
    "                             x,\n",
    "                             self.lin)\n",
    "        else:\n",
    "            y = torch.bmm(input=x,mat2=self.lin.data)\n",
    "        return y.permute(1, 0, 2).contiguous()\n",
    "         \n",
    "        \n",
    "class GraphLambda(nn.Module):\n",
    "    def __init__(self, fn, node_key='emb', edge_key='emb'):\n",
    "        super(GraphLambda, self).__init__()\n",
    "        self.fn = fn\n",
    "        self.edge_key = edge_key\n",
    "        self.node_key = node_key\n",
    "    \n",
    "    def forward(self, g):\n",
    "        if self.node_key:\n",
    "            g.ndata[self.node_key] = self.fn(g.ndata[self.node_key])\n",
    "        if self.edge_key:\n",
    "            g.edata[self.edge_key] = self.fn(g.edata[self.edge_key])\n",
    "        return g\n",
    "    \n",
    "ReduceMean = lambda: GraphLambda(lambda x: x.mean(dim=-2))\n",
    "ReduceCat = lambda: GraphLambda(lambda x: x.view(x.shape[0], -1))\n",
    "\n",
    "    \n",
    "class GatedResidual(nn.Module):\n",
    "    def __init__(self, module, node_dim, edge_dim):\n",
    "        super(GatedResidual, self).__init__()\n",
    "        self.module = module\n",
    "        sig_gain = nn.init.calculate_gain('sigmoid')\n",
    "        self.prev_node_gate = Linear(\n",
    "            node_dim, node_dim, bias=False,\n",
    "            init=ct.curry(nn.init.xavier_normal_)(gain=sig_gain))\n",
    "        self.curr_node_gate = Linear(\n",
    "            node_dim, node_dim, bias=True,\n",
    "            init=ct.curry(nn.init.xavier_normal_)(gain=sig_gain))\n",
    "        self.prev_edge_gate = Linear(\n",
    "            edge_dim, edge_dim, bias=False,\n",
    "            init=ct.curry(nn.init.xavier_normal_)(gain=sig_gain))\n",
    "        self.curr_edge_gate = Linear(\n",
    "            edge_dim, edge_dim, bias=True,\n",
    "            init=ct.curry(nn.init.xavier_normal_)(gain=sig_gain))\n",
    "        nn.init.zeros_(self.curr_node_gate.bias.data)\n",
    "        nn.init.zeros_(self.curr_edge_gate.bias.data)\n",
    "    \n",
    "    def forward(self, g):\n",
    "        prev_node = g.ndata['emb']\n",
    "        prev_edge = g.edata['emb']\n",
    "        \n",
    "        g = self.module(g)\n",
    "        \n",
    "        node_z = torch.sigmoid(\n",
    "            self.prev_node_gate(prev_node) + \\\n",
    "            self.curr_node_gate(g.ndata['emb']))\n",
    "        edge_z = torch.sigmoid(\n",
    "            self.prev_edge_gate(prev_edge) + \\\n",
    "            self.curr_edge_gate(g.edata['emb']))\n",
    "        g.ndata['emb'] = node_z * g.ndata['emb'] + (1 - node_z) * prev_node\n",
    "        g.edata['emb'] = edge_z * g.edata['emb'] + (1 - edge_z) * prev_edge\n",
    "        \n",
    "        return g\n",
    "    \n",
    "      \n",
    "class TripletMultiLinear(nn.Module):\n",
    "    def __init__(self, in_node_dim, in_edge_dim, out_edge_dim, n_lins, bias=False):\n",
    "        super(TripletMultiLinear, self).__init__()\n",
    "        self.lin = MultiLinear(in_node_dim * 2 + in_edge_dim, out_edge_dim, n_lins, bias)\n",
    "        \n",
    "    def triplet_linear(self, edges):\n",
    "        triplets = torch.cat([edges.src['emb'], edges.data['emb'], edges.dst['emb']], dim=-1)\n",
    "        return { 'triplets' : triplets }\n",
    "    \n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.triplet_linear)\n",
    "        g.edata['emb'] = self.lin(g.edata.pop('triplets'))\n",
    "        return GraphLambda(lambda x: x.view(x.shape[0], -1), node_key=None)(g)\n",
    "\n",
    "\n",
    "class TripletCat(nn.Module):\n",
    "    def __init__(self, out='emb'):\n",
    "        super(TripletCat, self).__init__()\n",
    "        self.out = out\n",
    "\n",
    "    def triplet_linear(self, edges):\n",
    "        triplets = torch.cat([edges.src['emb'], edges.data['emb'], edges.dst['emb']], dim=-1)\n",
    "        return { self.out : triplets }\n",
    "    \n",
    "    def forward(self, g):\n",
    "        g.apply_edges(self.triplet_linear)\n",
    "        return g\n",
    "    \n",
    "\n",
    "class MagicAttn(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, n_heads, attn_key='emb', msg_key='emb', alpha=.2):\n",
    "        super(MagicAttn, self).__init__()\n",
    "        self.attn = MultiLinear(\n",
    "            edge_dim, 1, n_heads, bias=False,\n",
    "            init=ct.curry(nn.init.xavier_normal_)(gain=nn.init.calculate_gain('leaky_relu', alpha)))\n",
    "        self.leaky_relu = nn.LeakyReLU(alpha)\n",
    "        self.n_heads = n_heads\n",
    "        self.softmax = EdgeSoftmax.apply\n",
    "        self.attn_key = attn_key\n",
    "        self.msg_key = msg_key\n",
    "        \n",
    "    def forward(self, g):\n",
    "        alpha_prime = self.leaky_relu(self.attn(g.edata[self.attn_key]))\n",
    "        g.edata['a'] = self.softmax(g, alpha_prime) * g.edata['emb'].view(g.edata['emb'].shape[0], self.n_heads, -1)\n",
    "        attn_emb = g.ndata[self.msg_key]\n",
    "        if attn_emb.ndimension() == 2:\n",
    "            g.ndata[self.msg_key] = attn_emb.view(g.number_of_nodes(), self.n_heads, -1)\n",
    "        g.update_all(fn.src_mul_edge(self.msg_key, 'a', 'm'), fn.sum('m', 'emb'))\n",
    "        return GraphLambda(lambda x: x.view(x.shape[0], -1))(g)\n",
    "\n",
    "      \n",
    "def NodeLinear(in_features, out_features, bias=False):\n",
    "    return GraphLambda(Linear(in_features, out_features, bias), edge_key=None)\n",
    "\n",
    "\n",
    "def EdgeLinear(in_features, out_features, bias=False):\n",
    "    return GraphLambda(Linear(in_features, out_features, bias), node_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56mrPBXa4a7l"
   },
   "outputs": [],
   "source": [
    "class MathDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MathDict, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def __op__(self, other, op):\n",
    "        if isinstance(other, dict):\n",
    "            return MathDict({ k: op(v, other[k]) for k, v in self.items() })\n",
    "        if isinstance(other, (numbers.Number, torch.Tensor)):\n",
    "            return MathDict({ k: op(v, other) for k, v in self.items() })\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        return self.__op__(other, op=operator.add)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return self.__op__(other, op=operator.mul)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self.__op__(other, op=operator.sub)\n",
    "    \n",
    "    def __mod__(self, other):\n",
    "        return self.__op__(other, op=operator.mod)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return self.__op__(other, op=operator.truediv)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.__op__(other, op=operator.lt)\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.__op__(other, op=operator.le)\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.__op__(other, op=operator.gt)\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.__op__(other, op=operator.ge)\n",
    "\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    global start_epoch, i, prefix, batch_size\n",
    "    net.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RF19lG0Orx7-"
   },
   "source": [
    "## Code for extracting outputs from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcOSeT3s4a7p"
   },
   "outputs": [],
   "source": [
    "ctype_means = torch.tensor([\n",
    "    94.97615286418801, 47.47988448446838, -0.2706244378832182,\n",
    "    -10.28660516398165, 3.124753613418501,3.6884695895354453,\n",
    "    4.771023359735822, 0.9907298624943462], dtype=torch.float32)\n",
    "ctype_stds = torch.tensor([\n",
    "    18.277236880290143, 10.922171556272271, 4.523610750196489,\n",
    "    3.9796071637303525, 3.6734741723096023, 3.0709074866562185,\n",
    "    3.7049844341285763, 1.3153933535337567], dtype=torch.float32)\n",
    "\n",
    "\n",
    "ctype_means_c = ctype_means.cuda()\n",
    "ctype_stds_c = ctype_stds.cuda()\n",
    "ones = torch.tensor([1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float32).cuda()\n",
    "\n",
    "\n",
    "def get_outputs(g, id_col='train_id', norm_truth=False, denorm_out=False, scaled=True):\n",
    "    labeled = g.edata['coupling_type'] != -1\n",
    "    out = g.edata['emb'][labeled].squeeze()\n",
    "    truth = g.edata['coupling'][labeled]\n",
    "    ctype = g.edata['coupling_type'][labeled]\n",
    "    if scaled:\n",
    "      stds = ctype_stds_c\n",
    "    else:\n",
    "      stds = ones\n",
    "    \n",
    "    if norm_truth:\n",
    "        truth = (truth - ctype_means_c[ctype])/stds[ctype]\n",
    "      \n",
    "    if denorm_out:\n",
    "        out = out * stds[ctype].unsqueeze(-1) + ctype_means_c[ctype].unsqueeze(-1)\n",
    "      \n",
    "    src, dst = g.all_edges('uv')\n",
    "    src, dst = src[labeled].to(out.device), dst[labeled].to(out.device)\n",
    "    tid = g.edata[id_col][labeled]\n",
    "\n",
    "    return out, ctype, truth, src, dst, tid\n",
    "        \n",
    "        \n",
    "def bidir_combine(out, ctype, truth, src, dst, tid):\n",
    "    fwd = src > dst\n",
    "    bwd = src < dst\n",
    "    outs = (out[fwd] + out[bwd]) / 2.\n",
    "    return outs, ctype[fwd], truth[fwd], src[fwd], dst[fwd], tid[fwd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWSgAq7Rr7VU"
   },
   "source": [
    "## Model arhitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npJBrRic4a73"
   },
   "outputs": [],
   "source": [
    "combine_fn = bidir_combine\n",
    "\n",
    "emb = 48\n",
    "heads = 24\n",
    "bias = False\n",
    "\n",
    "def AttnBlock(in_emb, out_emb):\n",
    "    return nn.Sequential(\n",
    "        EdgeLinear(in_emb, out_emb),\n",
    "        NodeLinear(in_emb, out_emb),\n",
    "        GraphLambda(lambda x: x.view(x.shape[0], heads, -1)),\n",
    "        TripletCat(out='triplet'),\n",
    "        MagicAttn(emb, 3 * emb, heads, attn_key='triplet'),\n",
    "        TripletMultiLinear(emb, emb, emb, heads, bias=bias),\n",
    "        GraphLambda(torch.nn.LayerNorm(heads * emb))\n",
    "    )\n",
    "\n",
    "net = nn.Sequential(\n",
    "    Embed(emb, emb),\n",
    "    AttnBlock(emb, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    GatedResidual(AttnBlock(emb * heads, emb * heads), emb * heads, emb * heads), GraphLambda(nn.PReLU()),\n",
    "    EdgeLinear(emb * heads, 512, bias=True), GraphLambda(nn.PReLU(), node_key=None),\n",
    "    EdgeLinear(512, 8, bias=True)\n",
    ")\n",
    "\n",
    "\n",
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGb7gcNGr_u9"
   },
   "source": [
    "## Making the predctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSqeqc-i51on"
   },
   "outputs": [],
   "source": [
    "def predict(test_data, net, scaled):\n",
    "    loader = torch.utils.data.DataLoader(test_data, batch_size=512, \n",
    "                                         shuffle=False, num_workers=2, \n",
    "                                         collate_fn=make_graph_batch(precision='single'))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        outs_d = []\n",
    "        for batch in tqdm(loader):\n",
    "            batch.to(next(net.parameters()).device)\n",
    "            g = net(batch)\n",
    "            outs = get_outputs(g, id_col='test_id', denorm_out=True, scaled=scaled)\n",
    "            outs = bidir_combine(*outs)\n",
    "            outs_d.append([t.detach().cpu() for t in outs])\n",
    "        outs_d = zip(*outs_d)\n",
    "        outs_d = [torch.cat(ts) for ts in outs_d]\n",
    "        out, ctype, truth, src, dst, tid = outs_d\n",
    "        return tid, out, ctype\n",
    "\n",
    "      \n",
    "def save_df(tid, pred, ctype, ctype_name, output):\n",
    "    ctype_idx = CTYPES.index(ctype_name)\n",
    "    df = pd.DataFrame({'tid': tid.numpy(), \n",
    "                       'val': pred[:, ctype_idx].numpy(), \n",
    "                       'ctype': ctype.numpy()})\n",
    "    df[df.ctype==ctype_idx].reset_index().to_csv(output)\n",
    "    \n",
    "    \n",
    "def mean_folds(folds):\n",
    "  dfs = [pd.read_csv(f) for f in folds]\n",
    "  dfs[0]['val'] = pd.concat([d['val'] for d in dfs], axis=1).mean(axis=1)\n",
    "  return dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 819052,
     "status": "ok",
     "timestamp": 1567284860187,
     "user": {
      "displayName": "Goran Rakocevic",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUktqkpJY0qFKtpI6DuRekptNOOnmdXwvcQokR=s64",
      "userId": "16829807710678167120"
     },
     "user_tz": -120
    },
    "id": "WRl-cq5gAhSn",
    "outputId": "ba7d9724-fab0-49df-a987-9f1333dd3f5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 5/90 [00:26<07:48,  5.52s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {ct: [] for ct in models.keys()}\n",
    "\n",
    "for ct_name, ms in models.items():\n",
    "  for i, (model, scaled) in enumerate(ms):\n",
    "    load_checkpoint(model)\n",
    "    tid, pred, ctype = predict(test_data, net, scaled)\n",
    "    save_df(tid, pred, ctype, ct_name, f'{output}/{ct_name}_{i}.csv')\n",
    "    results[ct_name].append( f'{ct_name}_{i}.csv')\n",
    "    \n",
    "    \n",
    "df = pd.concat([mean_folds(results[x]) for x in CTYPES])\n",
    "df.sort_values('tid', inplace=True)\n",
    "\n",
    "df = pd.DataFrame({'id': df.tid, 'scalar_coupling_constant': df.val})\n",
    "print(len(df))\n",
    "\n",
    "df.to_csv(f'{output}/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkbxmCaS6zmQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predict.ipynb",
   "provenance": [
    {
     "file_id": "172ljJk_j-dNwnM1k4RoUpR9rXgikHqRj",
     "timestamp": 1563974089105
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
